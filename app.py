import streamlit as st
from langchain_groq import ChatGroq
from langchain_community.vectorstores import Chroma
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
import os

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
st.set_page_config(page_title="ğŸ¤– Ø´Ø§Øª Ø¨ÙˆØª Ø¨Ø¨ÙŠØ§Ù†Ø§ØªÙƒ", layout="centered")
st.title("ğŸ¤– Ø´Ø§Øª Ø¨ÙˆØª Ø¨Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø§Ù„Ø®Ø§ØµØ©")

# --- Ù‚Ø±Ø§Ø¡Ø© Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API Ù…Ù† Ø§Ù„Ø£Ø³Ø±Ø§Ø± (Secrets) ---
# Ù„Ù† Ù†Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…ÙØªØ§Ø­ØŒ Ø³Ù†Ù‚Ø±Ø£Ù‡ Ù…Ù† st.secrets
try:
    GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
except KeyError:
    st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Groq API Key ÙÙŠ Ø§Ù„Ø£Ø³Ø±Ø§Ø± (Secrets)!")
    st.info("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¶Ø§ÙØ© GROQ_API_KEY Ø¥Ù„Ù‰ Ø£Ø³Ø±Ø§Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ Streamlit Cloud.")
    st.stop()

# --- Ø¯Ø§Ù„Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ Retriever ---
# (Ù†ÙØ³ Ø§Ù„Ø¯Ø§Ù„Ø©ØŒ Ù„Ø§ ØªØºÙŠÙŠØ±)
@st.cache_resource
def load_and_process_data(_file_content):
    try:
        file_content_as_string = _file_content.decode("utf-8")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        docs_splits = text_splitter.create_documents([file_content_as_string])
        
        # Ø³ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø£ÙˆÙ„ Ù…Ø±Ø© ÙÙ‚Ø·
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        vector_store = Chroma.from_documents(docs_splits, embeddings)
        
        return vector_store.as_retriever(search_kwargs={"k": 3})
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        return None

# --- Ø¯Ø§Ù„Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø³Ù„Ø³Ù„Ø© RAG ---
# (Ù†ÙØ³ Ø§Ù„Ø¯Ø§Ù„Ø©ØŒ Ù„Ø§ ØªØºÙŠÙŠØ±)
def get_rag_chain(retriever, llm):
    template = """
    Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©.
    Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© (Context) Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….
    Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¬ÙˆØ§Ø¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªØŒ Ù‚Ù„ "Ø£Ù†Ø§ Ø¢Ø³ÙØŒ Ù„ÙŠØ³ Ù„Ø¯ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ù‡Ø°Ø§".
    Ù„Ø§ ØªØ­Ø§ÙˆÙ„ Ø§Ø®ØªÙ„Ø§Ù‚ Ø¥Ø¬Ø§Ø¨Ø©.

    Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (Context):
    {context}
    Ø§Ù„Ø³Ø¤Ø§Ù„:
    {question}
    Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…ÙÙŠØ¯Ø© (Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©):
    """
    prompt = ChatPromptTemplate.from_template(template)
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain

# --- Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (ØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡) ---

# 1. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (LLM)
llm = ChatGroq(
    api_key=GROQ_API_KEY,
    model="llama-3.1-8b-instant", # Ø£Ø­Ø¯Ø« Ù…ÙˆØ¯ÙŠÙ„
    temperature=0.7
)

# 2. Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª "data.txt" Ø§Ù„Ø«Ø§Ø¨Øª
try:
    with open("data.txt", "rb") as f: # "rb" = read bytes
        file_bytes = f.read()
    
    # Ø±Ø³Ø§Ù„Ø© Ù„Ù„Ù€ "Ø£ÙˆÙ„ Ù…Ø±Ø©" ÙÙ‚Ø· Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    with st.spinner("...Ø¬Ø§Ø±ÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Ø£ÙˆÙ„ Ù…Ø±Ø© ÙÙ‚Ø·)"):
        retriever = load_and_process_data(file_bytes)

except FileNotFoundError:
    st.error("Ø§Ù„Ù…Ù„Ù 'data.txt' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.")
    st.stop()

if retriever:
    # 3. Ø¥Ù†Ø´Ø§Ø¡ Ø³Ù„Ø³Ù„Ø© RAG
    rag_chain = get_rag_chain(retriever, llm)

    # 4. Ø¥Ø¹Ø¯Ø§Ø¯ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø´Ø§Øª
    if "messages" not in st.session_state:
        st.session_state.messages = [
            AIMessage(content="Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! Ø£Ù†Ø§ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„ØªÙƒ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©.")
        ]

    # 5. Ø¹Ø±Ø¶ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø´Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    for message in st.session_state.messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.write(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.write(message.content)

    # 6. Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    if prompt := st.chat_input("Ø§Ø³Ø£Ù„ Ø£ÙŠ Ø´ÙŠØ¡ Ø¹Ù† Ù…Ù„ÙÙƒ..."):
        st.session_state.messages.append(HumanMessage(content=prompt))
        with st.chat_message("user"):
            st.write(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("... Ø£ÙÙƒØ±"):
                response = rag_chain.invoke(prompt)
                st.write(response)
        
        st.session_state.messages.append(AIMessage(content=response))